{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "34eba1dc6d9244cf84130c9e3842f07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f60ba7b756944111ae849476532137b2",
              "IPY_MODEL_db7353983be249ed8d235fd2ad2b8317",
              "IPY_MODEL_b4ecdd03e5a0408f930fbbcab7babbb5"
            ],
            "layout": "IPY_MODEL_436d7bc12b264489a8eb3cd57eb71e1a"
          }
        },
        "f60ba7b756944111ae849476532137b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a69a8bee8a44edbf0a54a372c46505",
            "placeholder": "​",
            "style": "IPY_MODEL_8dc37a3e89e44fd8a1b96d71163c5daa",
            "value": "100%"
          }
        },
        "db7353983be249ed8d235fd2ad2b8317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e748744e688b453fb1e7dee9ece90709",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cec551ef7e740b79e5290aeb4517d66",
            "value": 2
          }
        },
        "b4ecdd03e5a0408f930fbbcab7babbb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492282baefe94e8d84e8f8c8c557e662",
            "placeholder": "​",
            "style": "IPY_MODEL_846e95a18825428bad507a05f73f330f",
            "value": " 2/2 [00:00&lt;00:00,  9.35it/s]"
          }
        },
        "436d7bc12b264489a8eb3cd57eb71e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a69a8bee8a44edbf0a54a372c46505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc37a3e89e44fd8a1b96d71163c5daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e748744e688b453fb1e7dee9ece90709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cec551ef7e740b79e5290aeb4517d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "492282baefe94e8d84e8f8c8c557e662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "846e95a18825428bad507a05f73f330f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1kiR7dS2MDa",
        "outputId": "a68d3d6c-b321-4063-da95-fd58690808d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.7/dist-packages (0.3.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.9.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2fH6bxsmyJh",
        "outputId": "018d76a0-cbff-4184-baa1-bfbed142692c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3medium_based_on_gpt2\", bos_token=\"<s>\", eos_token=\"</s>\")\n",
        "model = AutoModelForCausalLM.from_pretrained(r\"/content/drive/MyDrive/Model\", use_cache=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHrLpD232SEW",
        "outputId": "48f809c2-1446-4cd3-8035-10ebef3ac1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"csv\", data_files={\"train\": r\"/content/train_dataset.csv\", \"test\" : r\"/content/test_dataset.csv\"})\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "34eba1dc6d9244cf84130c9e3842f07c",
            "f60ba7b756944111ae849476532137b2",
            "db7353983be249ed8d235fd2ad2b8317",
            "b4ecdd03e5a0408f930fbbcab7babbb5",
            "436d7bc12b264489a8eb3cd57eb71e1a",
            "43a69a8bee8a44edbf0a54a372c46505",
            "8dc37a3e89e44fd8a1b96d71163c5daa",
            "e748744e688b453fb1e7dee9ece90709",
            "8cec551ef7e740b79e5290aeb4517d66",
            "492282baefe94e8d84e8f8c8c557e662",
            "846e95a18825428bad507a05f73f330f"
          ]
        },
        "id": "0rZvOV_Y2T7n",
        "outputId": "d923e85e-3126-4ec4-8b10-53727a86716b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-3751b25a2a2ff5d9\n",
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/csv/default-3751b25a2a2ff5d9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34eba1dc6d9244cf84130c9e3842f07c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 2082\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 520\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 2048\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"])\n",
        "\n",
        "def group_texts(examples):\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    total_length = (total_length // block_size) * block_size\n",
        "    result = {\n",
        "        k: [t[i: i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    return result\n",
        "\n",
        "column_names = dataset[\"train\"].column_names\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=column_names,\n",
        ")\n",
        "result_dataset = tokenized_datasets.map(group_texts, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mKl-rMk2Wq6",
        "outputId": "cb7a4457-bb90-44ae-9d28-d048d169c5c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-3751b25a2a2ff5d9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-1eefa38856612530.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-3751b25a2a2ff5d9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-c3e86d1d9de7c0d1.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-3751b25a2a2ff5d9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-80b605b633a6ed62.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-3751b25a2a2ff5d9/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2dceea1b1f8e4e58.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False\n",
        "    )\n",
        "print(result_dataset.shape)\n",
        "tokenized_datasets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO8pGIm-2YX0",
        "outputId": "f26469ed-26e9-45d1-c699-c2dac61e9ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': (33, 2), 'test': (10, 2)}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (2082, 2), 'test': (520, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.all_special_tokens)\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSyy6lgQqX7g",
        "outputId": "ba4e98c1-4c2f-449a-f646-c1ff0a37459f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '</s>', '<|endoftext|>', '</s>']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizerFast(name_or_path='sberbank-ai/rugpt3medium_based_on_gpt2', vocab_size=50257, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '</s>'})"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    overwrite_output_dir=True,\n",
        "    gradient_accumulation_steps=4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    learning_rate=5e-5,\n",
        "    fp16=True,\n",
        "    num_train_epochs=20,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps = 100,\n",
        "    save_total_limit = 3,\n",
        "    load_best_model_at_end=True,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model, \n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"], \n",
        "    eval_dataset = tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    )\n",
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive/MyDrive/TrainModel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "evydu-Kg2bAt",
        "outputId": "972f132b-8fe4-4f90-b89c-7e22d60ff8d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2082\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 10400\n",
            "  Number of trainable parameters = 355871744\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9434' max='10400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 9434/10400 1:52:20 < 11:30, 1.40 it/s, Epoch 18.14/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.291186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.320421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.305661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.286871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.143619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.217131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.157073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.155322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.211659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.162163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.295929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.123322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.012549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.122736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.131970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.301261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.261975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.256816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.275798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.109958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.192841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.138912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.123687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.131628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.110474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.059585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.317391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.266096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.314490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.251084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.242774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.291859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.324409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.337782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.257511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.229845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.414310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.388073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.299094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.297244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.283877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.369999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.342768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.314803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.280903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.190323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.248400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.289935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.212090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.286161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.243309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.185421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.384876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.273862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.325506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.275139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.295084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.364904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.330529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.330049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.351057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.432477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.449818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.386658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.369494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.442461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.456150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.452604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.423446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.402294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.435593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.497788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.503623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.499353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.469453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.478054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.530706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.544131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.534216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.505903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.498972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.522748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.537588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.539186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.548406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.534471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.532897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.552218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.560675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.559215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.564680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.564826</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-500\n",
            "Configuration saved in test_trainer/checkpoint-500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-1000\n",
            "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-1500\n",
            "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-2000\n",
            "Configuration saved in test_trainer/checkpoint-2000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-2500\n",
            "Configuration saved in test_trainer/checkpoint-2500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-2500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-3000\n",
            "Configuration saved in test_trainer/checkpoint-3000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-3000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-1500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-3500\n",
            "Configuration saved in test_trainer/checkpoint-3500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-3500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-2500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-4000\n",
            "Configuration saved in test_trainer/checkpoint-4000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-4000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-3000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-4500\n",
            "Configuration saved in test_trainer/checkpoint-4500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-4500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-3500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-5000\n",
            "Configuration saved in test_trainer/checkpoint-5000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-5000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-5500\n",
            "Configuration saved in test_trainer/checkpoint-5500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-5500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-4500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-6000\n",
            "Configuration saved in test_trainer/checkpoint-6000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-6000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-5000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-6500\n",
            "Configuration saved in test_trainer/checkpoint-6500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-6500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-5500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-7000\n",
            "Configuration saved in test_trainer/checkpoint-7000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-7000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-6000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-7500\n",
            "Configuration saved in test_trainer/checkpoint-7500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-7500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-6500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-8000\n",
            "Configuration saved in test_trainer/checkpoint-8000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-8000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-7000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-8500\n",
            "Configuration saved in test_trainer/checkpoint-8500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-8500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-7500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-9000\n",
            "Configuration saved in test_trainer/checkpoint-9000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-9000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-8000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10400' max='10400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10400/10400 2:04:08, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.291186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.320421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.305661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.286871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.143619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.217131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.157073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.155322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.344900</td>\n",
              "      <td>6.211659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.162163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.295929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.123322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.012549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.360900</td>\n",
              "      <td>6.122736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.131970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.301261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.261975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.256816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.366300</td>\n",
              "      <td>6.275798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.109958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.192841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.138912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.123687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.361900</td>\n",
              "      <td>6.131628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.110474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.059585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.317391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.266096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.359800</td>\n",
              "      <td>6.314490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.251084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.242774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.291859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.324409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>6.337782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.257511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.229845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.414310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.388073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.357900</td>\n",
              "      <td>6.299094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.297244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.283877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.369999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.342768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>6.314803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.280903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.190323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.248400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.289935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>0.366100</td>\n",
              "      <td>6.212090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.286161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.243309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.185421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.384876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>0.380700</td>\n",
              "      <td>6.273862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.325506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.275139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.295084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.364904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>0.373500</td>\n",
              "      <td>6.344800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.330529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.330049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.351057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.432477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>6.449818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.386658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.369494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.379100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.442461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>0.364500</td>\n",
              "      <td>6.456150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.452604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.423446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.402294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.435593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>0.364000</td>\n",
              "      <td>6.497788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.503623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.499353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.469453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.478054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>0.350700</td>\n",
              "      <td>6.530706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.544131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.534216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.505903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.498972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>0.352200</td>\n",
              "      <td>6.522748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.537588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.539186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.548406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.534471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>0.348300</td>\n",
              "      <td>6.532897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.552218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.560675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.559215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.564680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>0.345300</td>\n",
              "      <td>6.564826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>6.569435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>6.573028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>6.576810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>6.577120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>6.577779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>0.340100</td>\n",
              "      <td>6.577868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10100</td>\n",
              "      <td>0.340100</td>\n",
              "      <td>6.578869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10200</td>\n",
              "      <td>0.340100</td>\n",
              "      <td>6.578653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10300</td>\n",
              "      <td>0.340100</td>\n",
              "      <td>6.578965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10400</td>\n",
              "      <td>0.340100</td>\n",
              "      <td>6.578871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-9500\n",
            "Configuration saved in test_trainer/checkpoint-9500/config.json\n",
            "Model weights saved in test_trainer/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-9500/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-8500] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "Saving model checkpoint to test_trainer/checkpoint-10000\n",
            "Configuration saved in test_trainer/checkpoint-10000/config.json\n",
            "Model weights saved in test_trainer/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in test_trainer/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in test_trainer/checkpoint-10000/special_tokens_map.json\n",
            "Deleting older checkpoint [test_trainer/checkpoint-9000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 520\n",
            "  Batch size = 1\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from test_trainer/checkpoint-2000 (score: 6.109957695007324).\n",
            "Saving model checkpoint to /content/drive/MyDrive/TrainModel\n",
            "Configuration saved in /content/drive/MyDrive/TrainModel/config.json\n",
            "Model weights saved in /content/drive/MyDrive/TrainModel/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/TrainModel/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/TrainModel/special_tokens_map.json\n"
          ]
        }
      ]
    }
  ]
}